---
title: "ML_PEM full workflow"
subtitle: "Step through all functions"
author: "W. H.MacKenzie"
date: "2023-06-19"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Set up new study area}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options:
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(  collapse = TRUE,  comment = "#>")
```

```{r setup, message=FALSE, warning=FALSE}
# remotes::install_github('bcgov/PEMr', build_vignettes = FALSE)

library(PEMr)
run_pemr()
library(PEMprepr)
library(ggplot2)
library(sf)
library(terra)
library(PEMsamplr)
require(clhs)
require(data.table)

devtools::load_all("D:\\GitHub\\PEMprepr")
devtools::load_all("D:\\GitHub\\PEMsamplr")
```

`PEMr`, short for _Predictive Ecosystem Mapping in R is a set of packages for developing a machine learning PEM following the process of MacKenzie et al. 
See [BC-BEC](https://www.for.gov.bc.ca/HRE/becweb/index.html)
and [`PEMr`](https://github.com/bcgov/PEMr) on _GitHub_for details about the BC BEC classification system and, the PEM Project.

In the example below it is assumed that you are running the following within a new R project.
## Project Set up. 
1) Set up a new R studio project for your PEM modelling. 
2) For each study area a folder structure based on your project/AOI name is constructed under this Rproject folder 

# Project folder setup
```{r create project folders}
project_name <- "Buck_AOI"
fid <- setup_folders(project_name)

```

##Add base data to the folders

Copy an aoi.gpkg (project boundary) into the Project /00_raw_inputs/10_vector/ folder.
```{r}

aoi_snap <- function(aoi, method=c("expand","shrink"), buffer=0){
  ## testing
  # setwd("e:/workspace/2019/PEM_2020/PEMWorkFlow/")
  #aoi <- sf::st_read("../data/Block_aoi.gpkg")
  bb <- sf::st_bbox(aoi)

  ## Function
  print("initial extent is:")
  print(bb)

  if (buffer>0 & method == "expand") {
    ## Generate expanded bbox -- expands to neared 100m
    xmin <- floor((bb$xmin - buffer) / 100)*100
    xmax <- ceiling((bb["xmax" ]+ buffer) / 100) * 100
    ymin <- floor((bb$ymin - buffer) / 100)*100
    ymax <- ceiling((bb["ymax"] + buffer) / 100) * 100


} else if (method == "expand") {
    ## Generate expanded bbox -- expands to neared 100m
    xmin <- floor(bb$xmin / 100)*100
    xmax <- ceiling(bb["xmax"] / 100) * 100
    ymin <- floor(bb$ymin / 100)*100
    ymax <- ceiling(bb["ymax"] / 100) * 100

  } else if (method == "shrink") {

    xmin <- ceiling(bb$xmin / 100)*100
    xmax <- floor(bb["xmax"] / 100) * 100
    ymin <- ceiling(bb$ymin / 100)*100
    ymax <- floor(bb["ymax"] / 100) * 100

  }

  box <- matrix(c(xmin, ymin, xmin, ymax, xmax, ymax, xmax, ymin, xmin, ymin), ncol = 2, byrow = TRUE)
  box <- sf::st_polygon(list(box))
  box <- sf::st_sfc(box, crs=sf::st_crs(aoi))
  box <- sf::st_as_sf(box)

  ## Report and Return
  print("Extent is:")
  print(sf::st_bbox(box))
  return(box)

}

```

```{r function to create aoi bounding box}

create_aoi <- function(aoi_dir = file.path(fid$shape_dir_0010[2]), 
                       out_dir = file.path(fid$shape_dir_1010[1]), 
                       aoi_vec = "aoi.gpkg",
                       buffer=1000){       ## input raster
aoi <- st_read(file.path(aoi_dir, aoi_vec))
aoi_bb <- aoi_snap(aoi, method = "expand")
aoi <- st_read(file.path(aoi_dir, aoi_vec))
aoi_ls <- aoi_snap_watershed(aoi, "expand")
aoi_buffered <- aoi_snap(aoi, method = "expand", buffer = buffer)
sf::st_write(aoi, file.path(out_dir,"aoi.gpkg"), append = FALSE)
sf::st_write(aoi_bb, file.path(out_dir,"aoi_snapped.gpkg"), append = FALSE)
sf::st_write(aoi_buffered, file.path(out_dir,"aoi_buffered.gpkg"), append = FALSE)
sf::st_write(aoi_ls, file.path(out_dir,"aoi_watershed.gpkg"), append = FALSE)
}

```


```{r create aoi bounding box}
create_aoi(buffer = 5000)
```

##Downloads AOI vector data from BC Data catalogue
A standard set of Vector data is used for subsequent sample planning and is based on the `aoi`.  This script collects numerous vector layers from the [BC Data Catalogue](https://catalogue.data.gov.bc.ca) making use of the [`bcdata`](https://github.com/bcgov/bcdata) package. Files are saved in _geopackage_ format.
Other option would be to simply point to an raw folder where files have been copied and snap all those layers

```{r, eval=FALSE}
###----changed default parameters for file locations and added output list
#devtools::load_all("D:\\GitHub\\PEMprepr")
create_base_vectors()
v <- list.files(path = fid$shape_dir_0010[1], pattern = ".gpkg", recursive = TRUE)
v
```


## Review data and make anyfixes
Once the vector data is reviewed and edited where appropriate we can save a final version in the "clean input data folder". 
```{r copy clean vectors function}
# copy_clean_vectors <- function(origindir = fid$shape_dir_0010[1], 
#                        targetdir = fid$shape_dir_1010[1], 
#                        aoi_vec = "aoi.gpkg"){       ## input raster
# filestocopy <- list.files(path = origindir, pattern = ".gpkg",
#     recursive = TRUE)
# lapply(filestocopy, function(x) file.copy(paste(origindir, x, sep = "/"),
#     paste(targetdir, x, sep = "/"), recursive = FALSE, copy.mode = TRUE))
# }
```


```{r copy reviewed layers to clean folders}
copy_clean_vectors()
```

## Create raster templates from AOI

The snapped `aoi` is used to create a raster template all generated covariates created to match selected template.

```{r create raster templates function}

create_template <- function(aoi_bb = file.path(fid$shape_dir_1010[1],
                                               "aoi_snapped.gpkg"), 
                            res,
                            outpath = fid$cov_dir_1020[2],
                            filename = "template.tif"){

  res_name = paste0(res, 'm')
  res_dir = file.path(outpath,res_name)
  #res$exists <- dir.exists(res_dir)
  if(dir.exists(res_dir) == FALSE) {

    print("creating folders")
    dir.create(res_dir, recursive = TRUE)
    print("folder structure created")
    
  } else {

    print(paste("The", as.character(res_dir), "folder already exists - returning folder names."))
    aoi_bb <- terra::vect(aoi_bb)
    template <- terra::rast(aoi_bb, resolution = res)
      terra::values(template) <- 0
    terra::writeRaster(template, file.path(outpath, res_name, filename), overwrite = TRUE)
  return(template)

    }
}

```


```{r create raster templates}
create_template(res = 5)
create_template(res = 25)
```

# Generation of raster covariates

Here we generate the terrain derived features for modelling.  This is powered by [SAGA-GIS](https://saga-gis.sourceforge.io/en/index.html).  
Covariates can be generated at multiple resolutions. The standard modelling for ML-PEM is at 5m scale.

1. Copy a dem.tif raster layer into the ./00_raw_inputs/20_dem/lidar folder.
2. Align the dem to the template.  resample the `dtm` to the desired resolution.
3. create the predictor covariates

## Import LiDAR DEM

```{r read in local LiDAR DEM}
dem <- terra::rast(file.path(fid$lidar_dir_00[2], "dem.tif"))
r5 <-  terra::rast(file.path(fid$cov_dir_1020, "/5m/template.tif"))
dem <- terra::project(dem, r5)
terra::writeRaster(dem, file.path(fid$cov_dir_1020[2], "/5m/dem.tif"), overwrite = TRUE)
plot(dem)
## or alternate get external TRIM data for DEM

```


```{r read in Trim DEM from bcmaps}
library(bcmaps)

get_trim_dem <- function(aoi_bb = file.path(fid$shape_dir_1010[2],"aoi_snapped.gpkg"),
                         template = file.path(fid$cov_dir_1020[2],res_name, "template.tif"),
                         res,
                         filename = "dem.tif",
                         out_dir = fid$cov_dir_1020[2]){
aoi <- st_read(aoi_bb)
  trim_raw <- bcmaps::cded_raster(aoi)
trim <- terra::rast(trim_raw)
res_name = paste0(res, 'm')
template_file <- template
template <- terra::rast(template_file)
trim <- terra::project(trim, template)
terra::writeRaster(trim, file.path(out_dir, res_name, filename), overwrite = TRUE)
}


```

```{r get TRIM dem at scales}
get_trim_dem(res = 5)
get_trim_dem(res = 25)
```

## Create the covariates

```{r, eval=FALSE}

layer_options <- c("sinksfilled", "sinkroute", "dem_preproc", "slope_aspect_curve",
               "tcatchment", "tca", "scatchment", "twi", "channelsnetwork",
               "overlandflow", "overlandflow2", "multiresflatness", "multiresflatness2",
               "multiresflatness3", "tri", "convergence", "openness",
               "dah", "tpi", "ridgevalley", "mrn", "flowaccumulation",
               "slopelength", "flowaccumulation2", "flowaccumulation3",
               "flowpathlength", "flowpathlength2", "flowpathlength3", "lsfactor",
               "solarrad", "convexity", "vertdistance", "tci_low",
               "swi", "windexp", "texture", "protection", "vrm",
               "mbi", "mscale_tpi", "relposition", "slopecurvatures",
               "steepestslope", "upslopearea")


  # run a test covariate
devtools::load_all("D:\\GitHub\\PEMprepr")

####add these a default parameters to create_covariates
sagapath = "C:/saga-9.0.2_x64/"
dem = file.path(fid$cov_dir_1020[2], "/5m/dem.tif")
create_covariates(dtm = dem,        ## raster created above
                  SAGApath = sagapath, ## Where SAGA GIS is installed
                  output = fid$cov_dir_1020[2], ## from the setup_folders above
                  layers = "sinksfilled")        ## test one is working 

# run all covariates 
create_covariates(dtm = dem,           ## raster created above
                  SAGApath = sagapath, ## Where SAGA GIS is installed
                  output = fid$cov_dir_1020[2], ## from the setup_folders above
                  layers = c( "all"))       ## use all or one of the above

##check the list of covariates. Notes these are saved in sdat format.

l <- list.files(path = fid$cov_dir_1020[2], pattern = ".sdat$",
                recursive = TRUE)

l
```

Create a bec raster to match the template sizes 

```{r create rast from vector using template}
###create function
# rasterize_to_template <- function(covar = "bec", field = "MAP_LABEL", template = r5){
#   if (class(covar)[1] == "sf") {
#     aoi <- terra::vect(aoi)
#   }
# covar_sf <- sf::st_read(file.path(fid$shape_dir_1010[2], paste0(covar, ".gpkg"))) %>%   sf::st_cast(., "MULTIPOLYGON")
# covar_code <- covar_sf %>% st_drop_geometry()  %>% dplyr::select(all_of(field)) %>%
#     unique() 
# covar_code <- covar_code %>% 
#     mutate(covar_unique_code = seq(1, length(covar_code[1]),1))
# covar_sf <- dplyr::left_join(covar_sf, covar_code)
# covar_vect <- terra::vect(covar_sf)
# covar_rast <- terra::rasterize(covar_vect, template)
# return(covar_rast)
# }
```


```{r}
#bec_ras5 <- rasterize_to_template()
bec_ras5 <- create_bgc_template()
terra::writeRaster(bec_ras5, file.path(fid$cov_dir_1020[2], "5m", "bec.tif"), overwrite = TRUE)
```

##BUILD FOR SAMPLE PLAN

## get TRIM for broader area for landscape and cost layers
```{r dem_cost function}
library(bcmaps)
get_trim_dem_cost <- function(aoi_bb = file.path(fid$shape_dir_1010[1],"aoi_buffered.gpkg"),
                         out_dir = fid$sampling_input_exclusion_raster[2],
                         filename = "dem_cost.tif"){
aoi = terra::vect(aoi_bb)
  template_cost <- terra::rast(aoi, resolution = 25)
      terra::values(template_cost) <- 0
aoi <- st_read(aoi_bb)
  trim_raw <- bcmaps::cded_raster(aoi)
  trim_raw <- terra::rast(trim_raw)
trim_cost <- terra::project(trim_raw, template_cost)
terra::writeRaster(trim_cost, file.path(out_dir, filename), overwrite = TRUE)
}

```


```{r}
get_trim_dem_cost()
```

```{r}
create_samplr_covariates <- function(dtm = file.path(fid$sampling_input_exclusion_raster[2], "dem_cost.tif"),
                                     #rtemplate = file.path(fid$cov_dir_1020[2],res_name, "template_buffered.tif"),
                                     SAGApath = sagapath,
                                     output = file.path(fid$sampling_input_landscape[2]),
                                     covariates = c("mrvbf", "dah", "landform"),
                                     sieve_size = 10,
                                     dah_threshold = 0.2,
                                     saga_param = list(T_SLOPE = 64, TPCTL_V = 6, T_PCTL_R = 2,
                                                    P_SLOPE = 4.0, P_PCTL = 3.0, UPDATE = 1,
                                                    CLASSIFY = 1, MAX_RES = 100)
                                     ){

  ##### Link SAGA to R --------------------------------------------------
  if(Sys.info()['sysname']=="Windows"){
    saga_cmd <- paste0(SAGApath, "saga_cmd.exe")
    fns      <- "\\" ### file name separator
  } else {
    saga_cmd <- "saga_cmd"
    fns      <- "/" ### file name separator

  }  ;
  z<- system(paste(saga_cmd, "-v"), intern = TRUE)  ## prints that SAGA version number -- confirming it works.
  z <- print(z)
  v <- suppressWarnings(as.numeric(unlist(strsplit(z, "[[:punct:][:space:]]+")[1])))
  v <- v[!is.na(v)][1:2]
  v <- as.numeric(paste(v[1], v[2], sep = "."))

  if (v < 7.6) {
    warning("SAGA-GIS is less that 7.6.  Not all covariates will generate.  Upgrade your SAGA, visit https://sourceforge.net/projects/saga-gis/files/")
  }


  # OUTPUTS: ------------------------------------------------------------
  ifelse(!dir.exists(file.path(output)),              #
         dir.create(file.path(output)), print("Directory Already Exists"))        #create tmpOut

  saga_tmp_files <- paste(output)
  ifelse(!dir.exists(file.path(saga_tmp_files)),              #if tmpOut Does not Exists
         dir.create(file.path(saga_tmp_files)), print("Directory Already Exists"))        #create tmpOut

  ## Convert to Saga format for processing ---------------------------------------
  dtm2 = terra::rast(dtm)
  rtemplate = terra::rast(dtm)
 terra::values(rtemplate) <- 0
  #sDTM <- "dtm.sdat"
  sDTM <- file.path(saga_tmp_files,"dtm.sdat")
  terra::writeRaster(dtm2, sDTM, overwrite = TRUE)



  ############ Covariate File Names #############################################
  ### This is ugly! re-write
  sDTM <- file.path(saga_tmp_files,"dtm.sdat")
  sinksroute <- file.path(saga_tmp_files, "sinkroute.sgrd")
  sinksfilled <- file.path(saga_tmp_files, "filled_sinks.sgrd")
  MRVBF <- file.path(saga_tmp_files, "mrvbf.sgrd")
  MRRTF <- file.path(saga_tmp_files, "mrrtf.sgrd")
  dah <- file.path(saga_tmp_files, "dah.sgrd")


  # fill sinks in DEM
  sysCMD <- paste(saga_cmd, "ta_preprocessor 5", "-ELEV" ,
                  sDTM,
                  "-FILLED", sinksfilled,
                  "-MINSLOPE ", 0.1
  )
  system(sysCMD)

  # set covariates to include all 3 covariates if no input is given

  if (is.null(covariates)) covariates <- c("mrvbf", "dah", "landform")
 ## 1.  Landscape MRVBF
  # http://www.saga-gis.org/saga_tool_doc/7.2.0/ta_morphometry_8.html

  if (any(covariates == "mrvbf")){

    # if (is.null(saga_param)){

      # saga_param <- list(T_SLOPE = 64, TPCTL_V = 6, T_PCTL_R = 2,
      #                    P_SLOPE = 4.0, P_PCTL = 3.0, UPDATE = 1,
      #                    CLASSIFY = 1, MAX_RES = 100)
    # }

  sysCMD <- paste(saga_cmd, "ta_morphometry 8", "-DEM",
                  sDTM,
                  "-MRVBF", MRVBF,
                  "-MRRTF", MRRTF,                       # Outputs
                  "-T_SLOPE", saga_param$T_SLOPE,
                  "-T_PCTL_V", saga_param$TPCTL_V,
                  "-T_PCTL_R", saga_param$T_PCTL_R,    # Default Parameters
                  "-P_SLOPE", saga_param$P_SLOPE,
                  "-P_PCTL", saga_param$P_PCTL,
                  "-UPDATE", saga_param$UPDATE,
                  "-CLASSIFY", saga_param$CLASSIFY,
                  "-MAX_RES", saga_param$MAX_RES
  )
  system(sysCMD)

  # sieve and then threshold

  mrvbf_r <- terra::rast(gsub(".sgrd", ".sdat", MRVBF)) %>%
    terra::sieve(threshold = sieve_size, directions=8)# %>%

  mrvbf_rcrop <- terra::crop(mrvbf_r, rtemplate)

  terra::writeRaster(mrvbf_r, file.path(saga_tmp_files, "mrvbf_LS.tif"), overwrite = TRUE)

}
  ## 2.  Landscape Diuranal Anisotropic Heating
  # http://www.saga-gis.org/saga_tool_doc/7.2.0/ta_morphometry_12.html


  if (any(covariates == "dah")){

  sysCMD <- paste(saga_cmd, "ta_morphometry 12", "-DEM",
                  sDTM,
                  "-DAH", dah,    # Output
                  "-ALPHA_MAX", 202.5   # Default Parameters
  )
  system(sysCMD)

  # reclass and threshold dah

  dah_r <- terra::rast(gsub(".sgrd", ".sdat", dah))

  # filter based on the 0.3 for Date Cree
  # - review the slope (style into three classes
  #                     - <25% slope or 0.43 radians,
  #                     - 45% slope or 0.43 - 0.78 radians
  #                     - >45% slope
  #                     - once this is stlyed then you can adjust the grouping on the DAH to match
  #                     - Deception = -0.2 to 0.2.
  #                     - Date Creek = -0.3 to 0.3.
  #                     - Peter Hope = -0.2 to 0.2

  m <- c( -10, (dah_threshold*-1), 1,
          (dah_threshold*-1 ), dah_threshold, 2,
          dah_threshold, 10,  3)
  rclmat <- matrix(m, ncol=3, byrow =TRUE)

  rc <- terra::classify(dah_r, rclmat)

  rc <- rc %>%
    terra::sieve(threshold = sieve_size, directions=8)

  rc_crop <- terra::crop(rc, rtemplate)

  terra::writeRaster(rc_crop, file.path(saga_tmp_files, "dah_LS.tif"), overwrite = TRUE)
}

  ## 3. Landform Class
  if (any(covariates == "landform")){
  land_class <- create_landform_classes(dtm2, scale = 75, sn = 3, ln = 7, n.classes = "six")

  # sieve landclass
  land_class <- land_class %>%
    terra::sieve(threshold = sieve_size, directions=8) %>%
    terra::subst(from = 0, to = NA)

  land_class <- terra::crop(land_class, rtemplate)
  names(land_class)<- "landclass"

  terra::writeRaster(land_class, file.path(saga_tmp_files, "landform_LS.tif"), overwrite = TRUE)

  # remove temp Saga files
  # unlink(paste(output, "saga", sep = "/"), recursive = TRUE)
  # delete the files
  }
  to_delete <- grep(".tif", list.files(file.path(saga_tmp_files), full.names = TRUE), value = T, invert = TRUE)
  file.remove(to_delete)

  return(TRUE)

}
```

## Create Landcape variables
```{r}
devtools::load_all("D:\\GitHub\\PEMsamplr")
sagapath = "C:/saga-9.0.2_x64/"
create_samplr_covariates()
                     
```
## Check landscape variables
```{r}
# generate landscape validation 

fileoi <- c("dah_LS.tif", "mrvbf_LS.tif", "landform_LS.tif")
outpath = file.path(fid$sampling_input_landscape[2])

filesoi <- list.files(outpath, full.names = TRUE)[list.files(outpath) %in% fileoi]

landscapes <- create_binned_landscape(outpath)

terra::plot(landscapes)

terra::writeRaster(landscapes, file.path(outpath, "landscape_variable_validation.tif"), overwrite = TRUE)


# Check the landscape distribution by bgc

becpath <-fid$shape_dir_1010[1]

bec <- sf::st_read(file.path(becpath, "bec.gpkg")) %>%
  sf::st_cast(., "MULTIPOLYGON") 

routdf <- check_bgc_landscapes(bec,landscapes)

ggplot2::ggplot(routdf, aes(landscape)) +
  ggplot2::geom_histogram() +
  ggplot2::facet_wrap(~MAP_LABEL)
```

```{r roads function}
get_cost_roads <- function(in_aoi = file.path(fid$shape_dir_1010[2],"aoi_buffered.gpkg"), 
                      out_path= file.path(fid$sampling_input_exclusion_vector[2]), 
                      filename = "road_network_cost.gpkg") {
  # The main road network layer has too many roads in it. Filter it down to only
  # include named roads and combine those with actual mapped FSR's

  #in_aoi = "aoi_cost.gpkg"
  aoi = st_read(in_aoi)
  message("\rDownloading Road network")
  roads <- bcdc_query_geodata("bb060417-b6e6-4548-b837-f9060d94743e") %>%
    bcdata::filter(BBOX(local(st_bbox(aoi)))) %>% # slightly larger extent
    bcdata::select(id, ROAD_NAME_FULL, ROAD_CLASS, ROAD_SURFACE, FEATURE_LENGTH_M) %>%
    collect() %>%
    dplyr::select(id, ROAD_NAME_FULL,ROAD_SURFACE, ROAD_CLASS,FEATURE_LENGTH_M) %>%
       {if(nrow(.) > 0) {
      st_intersection(., aoi) %>%
       st_cast("MULTILINESTRING")
    } else .}

  fsr <- bcdc_query_geodata("9e5bfa62-2339-445e-bf67-81657180c682") %>%
    bcdata::filter(
      BBOX(local(st_bbox(aoi)))) %>%
    collect() %>%
    dplyr::select(id, FILE_TYPE_DESCRIPTION, FEATURE_LENGTH_M) %>%
    dplyr::rename(ROAD_CLASS = FILE_TYPE_DESCRIPTION) %>%
    dplyr::mutate(ROAD_CLASS = dplyr::case_when(
      ROAD_CLASS == "Forest Service Road" ~ "resource",
      ROAD_CLASS == "Road Permit" ~ "unclassifed")) %>%
    dplyr::mutate(ROAD_SURFACE = dplyr::case_when(
    ROAD_CLASS == "resource" ~ "loose",
    ROAD_CLASS == "unclassifed" ~ "rough")) %>%
    {if(nrow(.) > 0) {
      st_intersection(., aoi) %>%
        st_cast("MULTILINESTRING")
    } else .}

  road_merge <- dplyr::bind_rows(roads, fsr)

  st_write(road_merge, file.path(out_path, filename), append = FALSE)
}
```
Download cost roads for larger area
```{r}
get_cost_roads()
```

### Get or make start point
```{r}

cities <- terra::vect(file.path(fid$shape_dir_1010, "major_towns_bc.gpkg"))
### this does not work if outside of AOI
nearest_town = "Houston"
start <- cities[cities$NAME == nearest_town,"NAME"]
###Or find starting point in QGIS on road and enter here
my.df <- read.table(text=" x    y
                       972620    1068774", header = TRUE)
# 1553304    475488", header = TRUE)

start <- st_as_sf(my.df, coords = c("x","y"),
                  crs = 3005) %>%
  as("Spatial")

mapview::mapview(start)
```


## Prepare conductance for cost layer


```{r Cost layer}
devtools::load_all("D:\\GitHub\\PEMsamplr")
dem <- terra::rast(file.path(fid$sampling_input_exclusion_raster[2], "dem_cost.tif"))
roads_network <- sf::st_read(file.path(fid$sampling_input_exclusion_vector[2], "road_network_cost.gpkg"), quiet = TRUE) %>%
  sf::st_zm()
plot(dem)
mapview::mapview(roads_network)
# check the roads layer
check_road_layer(roads_network)
mapview::mapview(roads_network)
## generate transition layer
costprep <- prep_cost_layers_lcp(x = dem,
                                 cost_function = "tobler offpath",
                                 neighbours = 16,
                                 roads = roads_network,
                                 crit_slope = 30,
                                 max_slope = 100,
                                 percentile = 0.5,
                                 exaggeration = FALSE)

```



```{r Cost layer function}
create_accum_cost <- function(x=costprep, origin, FUN = mean, rescale = FALSE) {

  cs_rast <- terra::rast(nrow = x$nrow, ncol = x$ncol, xmin = x$extent[1], xmax = x$extent[2], ymin = x$extent[3], ymax = x$extent[4],crs = x$crs)
#cs_rast <-terra::rast(x)
origins = terra::vect(origin)
  from_coords <- get_coordinates(origins)
  from_cell <- terra::cellFromXY(cs_rast, from_coords)

  cm_graph <- igraph::graph_from_adjacency_matrix(x$conductanceMatrix, mode = "directed", weighted = TRUE)

  igraph::E(cm_graph)$weight <- (1/igraph::E(cm_graph)$weight)

  from_distances <- igraph::distances(cm_graph, v = from_cell,  mode="out", algorithm = "dijkstra")

  accum_rasts <- c(rep(cs_rast, nrow(from_distances)))

  for(i in 1:terra::nlyr(accum_rasts))  {

    accum_rasts[[i]] <- terra::setValues(accum_rasts[[i]], from_distances[i,])

  }

  accum_rast <- terra::app(accum_rasts, fun = FUN)

  accum_rast[is.infinite(accum_rast)] <- NA

  if(rescale) {
    rast_min <- terra::minmax(accum_rast)[1]
    rast_max <- terra::minmax(accum_rast)[2]

    accum_rast <- ((accum_rast - rast_min)/(rast_max - rast_min))
  }

  return(accum_rast)

}
```

## Build raw cost layer
```{r build raw cost layer}
acost <- create_accum_cost(x = costprep, origin = start, FUN = min)
names(acost) = "cost"
plot(acost)
terra::writeRaster(acost, file.path(fid$sampling_input_landscape[2], "cost_raw.tif"), overwrite = TRUE)
```
## Adjust cost layer
```{r create_cost penalty fucntion}
create_cost_penalty <- function(vec_dir = file.path(fid$shape_dir_1010[2]), 
                                                    dem = file.path(fid$sampling_input_exclusion_raster[2], "dem_cost.tif"), 
                                                    cost = file.path(fid$sampling_input_landscape[2], "cost_raw.tif"), 
                                                    costval = 3000,
                                                    vri_cost = 2500, 
                                                    calc_by_qq = TRUE) {

.assign_highcost = function(shape, crs = 3005, costval, cost) {

  hcsf <- sf::st_read(shape) %>%
    sf::st_set_crs(crs) %>%
    dplyr::mutate(cost = costval) %>%
    dplyr::select(cost) %>%
    sf::st_buffer(dist = 150) %>%
    sf::st_cast("MULTIPOLYGON")

  rhc <- terra::rasterize( hcsf, cost, field = "cost", fun = "max")
  return(rhc)
}
  
 dem = terra::rast(dem) 
 cost = terra::rast(cost)


    if (calc_by_qq == T){

    qq <- terra::global(cost, quantile, probs = c(0.65, 0.70), na.rm = T)    # calculate 65% and 70% quantiles if determining the high cost threshold

    vri_cost <- qq$X65.
    costval <- qq$X70.

  }


  
  # 1. Assign high cost for cutblocks
  if(file.exists(file.path(vec_dir, "cutblocks.gpkg"))){
    rcutblock<- .assign_highcost(file.path(vec_dir, "cutblocks.gpkg"), costval = costval, cost = cost)
    hc <- terra::cover(rcutblock, cost)
  }

  # 2. Assign high cost to age class 1 and 2
  if(file.exists(file.path(vec_dir, "vri_class1_2.gpkg"))){
  rvri12_class <- .assign_highcost(file.path(vec_dir, "vri_class1_2.gpkg"), costval = costval, cost = cost)
  hc <- terra::cover( rvri12_class, hc)

  }

  # 3. Assign a slightly lower cost to age class 3.
  if(file.exists(file.path(vec_dir, "vri_class3.gpkg"))){
    rvri3_class <- .assign_highcost(file.path(vec_dir, "vri_class3.gpkg"), costval = vri_cost, cost = cost)
    hc <- terra::cover(rvri3_class, hc)
  }

  # for some AOIS;
  # 3a Assign a high cost to deciduous leading species area

  if(file.exists(file.path(vec_dir, "vri_decid.gpkg"))){

   rvri_decid <- .assign_highcost(file.path(vec_dir, "vri_decid.gpkg"), costval = costval,cost = cost)
   hc <- terra::cover( rvri_decid, hc )
  }

  # 4. Assign high cost to private lands
  if(file.exists(file.path(vec_dir, "private.gpkg"))){

  rpriv <- .assign_highcost(file.path(vec_dir, "private.gpkg"), costval = costval, cost = cost)
  hc <- terra::cover( rpriv, hc)
  }

  # 5. Add high cost for high and medium intensity fire areas or all fires
  if(file.exists(file.path(vec_dir, "fire_int.gpkg"))){
  rfireint <- .assign_highcost(file.path(vec_dir,"fire_int.gpkg"), costval = costval, cost = cost)
  hc <- terra::cover(hc, rfireint)
  }

  # 6. Add high cost for all fires
  if(file.exists(file.path(vec_dir, "fires.gpkg"))){
  rfires <- .assign_highcost(file.path(vec_dir,"fires.gpkg"), costval = costval, cost = cost)
  hc <- terra::cover(hc,rfires)

  }

  # 7. Assign high cost to transmission lines
  if(file.exists(file.path(vec_dir, "translines.gpkg"))){
  rtrans <- .assign_highcost(file.path(vec_dir,"translines.gpkg"), costval = costval, cost = cost)
  hc <- terra::cover(hc, rtrans)
  }


  # 8. Very steep areas
  slope <- terra::terrain(dem, v = "slope", neighbors = 8, unit = "degrees") # convert these radians to rise/run in next line
  # add a threshold value here
  # degrees (45 degrees = 100%, use around 30 degrees ~ 60% )

   m <- c( 0, 30, NA,
          30, 45, costval)

    rclmat <- matrix(m, ncol=3, byrow =TRUE)
    rc <- terra::classify(slope, rclmat)

    hc_out  <- terra::cover(rc, hc)
    names(hc_out)<- "cost"

    return(hc_out)

}

```

```{r}
cost_masked <- create_cost_penalty()
terra::writeRaster(cost_masked, 
                   file.path(fid$sampling_input_landscape[2],  
                             "cost.tif"), overwrite = TRUE)
```


# generate a BGC cost mask per BGC in map area

```{r}
create_bgc_mask <- function(vec_dir = file.path(fid$shape_dir_1010[2], "bec.gpkg"),
                            cost_masked = file.path(fid$sampling_input_landscape[2], "cost_penalty.tif"), 
                            out_dir = fid$sampling_input_exclusion_bgc[2]) {

  # exclude water:
  #bec<- sf::st_read(file.path(vec_dir, "bec.gpkg"))
  bec<- sf::st_read(vec_dir)
  boi <- unique(bec$MAP_LABEL)
  rcost_masked = terra::rast(cost_masked)
  

  for (b in boi) {
    # b = boi[1]

    subzone <- bec %>%
      dplyr::filter(MAP_LABEL %in% b)

    subzone_buff <- sf::st_buffer(subzone, dist = -150)

    boi_mask <- terra::mask(rcost_masked, subzone_buff)
    names(boi_mask) = 'cost'
    boi_mask <- 1 + (boi_mask *0)
    terra::writeRaster(boi_mask, file.path(out_dir, paste0(b,"_exclude_mask.tif")), overwrite = TRUE)

    mask_poly_boi <- terra::as.polygons(boi_mask, dissolve = TRUE)
    mask_poly_boi <- st_as_sf(mask_poly_boi)
    st_write(mask_poly_boi, file.path(out_dir,paste0(b, "_exclude_poly.gpkg")), delete_dsn = TRUE, overwrite = TRUE)
  }
  return(TRUE)

}
```

```{r}
#exclusion_path <- fid$sampling_input_exclusion[2]

create_bgc_mask()

```


##Generate AOI with binned landscape
```{r adjusted cost layer}
# Check costs by bgc vs binned landscape
# landscape <- terra::rast(file.path(outpath, "landscape_variable_validation.tif"))
# bgccost <- check_bgc_cost(bgc = bec,
#                           binned_landscape = landscape,
#                           cost = acost)
# 
# ggplot2::ggplot(bgccost, ggplot2::aes(landscape, fill = cost_code)) +
#   ggplot2::geom_histogram(bins = 30) +
#   ggplot2::facet_wrap(~MAP_LABEL)

# generate cost penalty
```


```{r clhs function}
 #devtools::install_github("kdaust/clhs") 
 require(clhs)
# require(data.table)
create_clhs <- function(all_cov, num_slices = 5, to_include = NULL,
                        n_points = 5, min_dist = 1000, num_sample = 5000000, cost = "cost"){
  if(num_slices < 1) stop("Hold up! Must have at least one slice.")

  layer_names <- names(all_cov)
  samp_dat <- terra::spatSample(all_cov , size = num_sample, method = "regular", xy = TRUE, as.df = F) # sample raster
  samp_dat <- samp_dat %>% mutate(cost = ifelse(cost == 0, NA , cost)) %>%  filter(!is.na(cost), !is.na(landclass))

  coords <- samp_dat[,c("x","y")]
  curr_dat <- samp_dat[,layer_names]

  ##setup initial data
  if(is.null(to_include)){ ##nothing to include
    inc_idx <- NULL
    size = n_points
  }else{
    inc_pts <- terra::extract(all_cov, to_include) ##test this
    inc_pts <- inc_pts[,-(1)]
    inc_pts <- sf::st_as_sf(inc_pts)
    inc_idx <- 1:nrow(inc_pts)
    size = n_points + nrow(inc_pts)
    curr_dat <- rbind(to_include, curr_dat) ##comine with inlcuded data
    include_coords <- st_coordinates(to_include)
    coords <- rbind(coords, include_coords)
  }

  if(num_slices == 1){
    message("Gen-R-ating one slice...")

    for(i in 1:5){
      templhs <- clhs(curr_dat, size = size,
                      must.include = inc_idx,
                      iter = 200000 ,
                      simple = FALSE,
                      progress = TRUE,
                      cost = cost,
                      use.cpp = T,
                      latlon = coords,
                      min.dist = min_dist)
      if(sum(templhs$final_obj_distance) == 0) break
    }


  }else{
    message("Gen-R-ating multiple slices...")
    #inc_idx = NULL
    for(snum in 1:num_slices){
       #snum = 1
      #
      for(i in 1:5){
        i=1
        templhs <- clhs(curr_dat,
                        size = snum * size,
                        must.include = inc_idx,
                        iter = 20000 ,
                        simple = FALSE,
                        progress = TRUE,
                        cost = "cost",
                        use.cpp = T,
                        latlon = coords,
                        min.dist = min_dist,
                        use.coords = FALSE)
        if(sum(templhs$final_obj_distance) == 0){
          break
        }else{
          message("Points too close. Trying again...")
        }
      }
      #print(templhs$final_obj_distance)
      inc_idx <- templhs$index_samples
      # print(templhs$final_obj_distance)
      # print(inc_idx)
    }
  }
  # uncomment to plot points and check distance
  if(any(templhs$final_obj_distance != 0))
    warning("Some points fall within minimum distance!")

  out <- as.data.table(samp_dat[templhs$index_samples,])
  out[,`:=`(slice_num = rep(num_slices:1,each = n_points),
             point_num = rep(1:n_points, times = num_slices))]
  out_sf <- st_as_sf(out,coords = c("x","y"),crs = 3005)
  #dist_mat <- st_distance(out_sf,out_sf)
  #plot(all_cov$cost)
  #points(vect(out_sf["slice_num"]))
  return(out_sf)
}
```

```{r}
###############################################################
# 1) generate clhs
#devtools::load_all("D:\\GitHub\\PEMsamplr")
clhs_outpath <- fid$samplingplan_clhs[2]

landscape_dir <- fid$sampling_input_landscape[2]

fileoi <- c("cost.tif", "dah_LS.tif", "mrvbf_LS.tif", "landform_LS.tif")

filesoi <- list.files(landscape_dir, full.names = TRUE)[list.files(landscape_dir) %in% fileoi]
all_cov <- terra::rast(filesoi)

aoi <- sf::st_read(file.path(fid$shape_dir_1010[2],"aoi.gpkg"))
aoi_buff <- terra::vect(aoi) %>% terra::buffer(-150)

roads <- sf::st_read(file.path(fid$sampling_input_exclusion_vector[2], "road_network_cost.gpkg"))
roads_buff <- terra::vect(roads) %>% terra::buffer(155)# road centre line + 10m for ROW + 145m for transect

water <-  aoi <- sf::st_read(file.path(fid$shape_dir_1010[2],"water.gpkg"))
water <- water %>% dplyr::filter(water$WATERBODY_TYPE == "L")
water_buff <- terra::vect(water) %>% terra::buffer(150)
# read in bec data
bec_dir = fid$sampling_input_exclusion_bgc[2]

boi <- list.files(bec_dir, pattern = ".gpkg")


for(b in boi) {
#b <- boi[1]
  boi_mask <- terra::vect(file.path(bec_dir, b)) 
  names(boi_mask) = "mask"
  bname <- gsub("_exclude_poly.gpkg", "", b)
  
  ## S4 method for signature 'SpatRaster,SpatVector'
# mask(x, mask, inverse=FALSE, updatevalue=NA,
# 	touches=TRUE, filename="", ...)
  
  sample_layers_masked <-  terra::mask(all_cov, boi_mask) 
  sample_layers_masked <-  terra::mask(sample_layers_masked, aoi_buff) 
  sample_layers_masked <-  terra::mask(sample_layers_masked, roads_buff, inverse = TRUE) 
    sample_layers_masked <-  terra::mask(sample_layers_masked, water_buff, inverse = TRUE) 
  sample_layers_masked_cost <- sample_layers_masked[[2:4]]
  sample_layers_masked <- sample_layers_masked[[1:4]]
   #  sample_layers_masked$landclass <- as.factor(sample_layers_masked$landclass)
   # sample_layers_masked$dah <- as.factor(sample_layers_masked$dah)
   #  sample_layers_masked$mrvbf <- as.factor(sample_layers_masked$mrvbf)
  terra::writeRaster(sample_layers_masked_cost, file.path(fid$samplingplan_clhs[2], paste0(bname,"_clhs_sample_mask_cost.tif")), overwrite = TRUE)

  # create 10 different sample plans
  for(rot in 1:5){ 
    rot = 5
    sample_points <- create_clhs(all_cov = sample_layers_masked, 
                                 num_slices = 5, 
                                 to_include = NULL, 
                                 n_points = 5, 
                                 min_dist = 100,
                                 num_sample = 500000,
                                 cost = "cost")
    sample_points <- sample_points #%>%   dplyr::mutate(bgc = bname)
    sf::st_write(sample_points, file.path(clhs_outpath, paste0("_clhs_sample_",rot,".gpkg")),append=FALSE )
    #sf::st_write(sample_points, file.path(clhs_outpath, paste0(bname, "_clhs_sample_",rot,".gpkg")),append=FALSE )
    
  }
  
} 

```

